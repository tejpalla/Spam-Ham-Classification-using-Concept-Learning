{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "umXeop1D0A3L",
    "outputId": "09a3af4c-56c2-4088-def1-f988fd8a8502"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             tree    logreg     Bayes\n",
      "1        0.911063  0.921909  0.809111\n",
      "2        0.906522  0.921739  0.791304\n",
      "3        0.932609  0.913043  0.819565\n",
      "4        0.900000  0.923913  0.828261\n",
      "5        0.930435  0.928261  0.810870\n",
      "6        0.895652  0.936957  0.813043\n",
      "7        0.902174  0.945652  0.797826\n",
      "8        0.943478  0.932609  0.815217\n",
      "9        0.928261  0.923913  0.817391\n",
      "10       0.897826  0.923913  0.830435\n",
      "avg      0.914802  0.927191  0.813302\n",
      "std_dev  0.016374  0.008699  0.011506\n",
      "             tree    logreg     Bayes\n",
      "1        0.045200  0.702000  0.003300\n",
      "2        0.065700  0.687300  0.002100\n",
      "3        0.057900  0.588100  0.005700\n",
      "4        0.058100  0.721200  0.001900\n",
      "5        0.053500  0.872100  0.006300\n",
      "6        0.063000  1.058800  0.002000\n",
      "7        0.069500  1.144600  0.001900\n",
      "8        0.069200  1.013400  0.002000\n",
      "9        0.062000  1.075700  0.005100\n",
      "10       0.084200  1.048900  0.001900\n",
      "avg      0.062830  0.891210  0.003220\n",
      "std_dev  0.009976  0.190958  0.001692\n",
      "             tree    logreg     Bayes\n",
      "1        0.885794  0.897143  0.794393\n",
      "2        0.883469  0.898876  0.786667\n",
      "3        0.915068  0.888889  0.808314\n",
      "4        0.875000  0.903581  0.815851\n",
      "5        0.911602  0.907042  0.802721\n",
      "6        0.868852  0.919220  0.802752\n",
      "7        0.877384  0.931129  0.790068\n",
      "8        0.928962  0.913165  0.804598\n",
      "9        0.908078  0.899135  0.805556\n",
      "10       0.872629  0.900285  0.814286\n",
      "avg      0.892684  0.905847  0.802520\n",
      "std_dev  0.020153  0.011688  0.009142\n",
      "          tree  logreg  Bayes\n",
      "1          2.0     1.0    3.0\n",
      "2          2.0     1.0    3.0\n",
      "3          1.0     2.0    3.0\n",
      "4          2.0     1.0    3.0\n",
      "5          1.0     2.0    3.0\n",
      "6          2.0     1.0    3.0\n",
      "7          2.0     1.0    3.0\n",
      "8          1.0     2.0    3.0\n",
      "9          1.0     2.0    3.0\n",
      "10         2.0     1.0    3.0\n",
      "avg_rank   1.6     1.4    3.0\n",
      "friedman statistic : 15.2\n",
      "There  is  statistically  significant difference in behaviour between the three models. Null Hypothesis is rejected\n",
      "The critical difference is :1.0478214542564015\n",
      "The performance of Decision Tree and Bayes is not equivalent.\n",
      "The performance of Bayes and Logistic Regression is not equivalent.\n",
      "          tree  logreg  Bayes\n",
      "1          2.0     3.0    1.0\n",
      "2          2.0     3.0    1.0\n",
      "3          2.0     3.0    1.0\n",
      "4          2.0     3.0    1.0\n",
      "5          2.0     3.0    1.0\n",
      "6          2.0     3.0    1.0\n",
      "7          2.0     3.0    1.0\n",
      "8          2.0     3.0    1.0\n",
      "9          2.0     3.0    1.0\n",
      "10         2.0     3.0    1.0\n",
      "avg_rank   2.0     3.0    1.0\n",
      "friedman statistic : 20.0\n",
      "There  is  statistically  significant difference in behaviour between the three models. Null Hypothesis is rejected\n",
      "The critical difference is :1.0478214542564015\n",
      "The performance of Bayes and Logistic Regression is not equivalent.\n",
      "          tree  logreg  Bayes\n",
      "1          2.0     1.0    3.0\n",
      "2          2.0     1.0    3.0\n",
      "3          1.0     2.0    3.0\n",
      "4          2.0     1.0    3.0\n",
      "5          1.0     2.0    3.0\n",
      "6          2.0     1.0    3.0\n",
      "7          2.0     1.0    3.0\n",
      "8          1.0     2.0    3.0\n",
      "9          1.0     2.0    3.0\n",
      "10         2.0     1.0    3.0\n",
      "avg_rank   1.6     1.4    3.0\n",
      "friedman statistic : 15.2\n",
      "There  is  statistically  significant difference in behaviour between the three models. Null Hypothesis is rejected\n",
      "The critical difference is :1.0478214542564015\n",
      "The performance of Decision Tree and Bayes is not equivalent.\n",
      "The performance of Bayes and Logistic Regression is not equivalent.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from time import time\n",
    "import math\n",
    "from math import sqrt\n",
    "import statistics\n",
    "from sklearn.metrics import accuracy_score,f1_score\n",
    "from sklearn.tree import  DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB \n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    " \n",
    "#read spambase.csv file\n",
    "\n",
    "data_file = pd.read_csv('spambase.csv')\n",
    "x = data_file.iloc[:,:-1]\n",
    "y = data_file.iloc[:,-1]\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True)\n",
    "kfold.get_n_splits(x, y)\n",
    "#initialising models\n",
    "tree = DecisionTreeClassifier()\n",
    "logreg = LogisticRegression(max_iter=5000)\n",
    "Bayes = GaussianNB()\n",
    "#empty lists to hold measures of metrics over 10 folds\n",
    "train_time_tree=[]\n",
    "accuracy_tree=[]\n",
    "f1_tree=[]\n",
    "\n",
    "train_time_logreg=[]\n",
    "accuracy_logreg=[]\n",
    "f1_logreg=[]\n",
    "\n",
    "train_time_Bayes=[]\n",
    "accuracy_Bayes=[]\n",
    "f1_Bayes=[]\n",
    "#running 10 fold cross validation\n",
    "for train_index, test_index in kfold.split(x, y):\n",
    "    x_train, x_test = x.iloc[train_index], x.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    # Decision Tree\n",
    "    start1=time()                             \n",
    "    tree.fit(x_train,y_train)\n",
    "    stop1=time()                              \n",
    "    time1=round(stop1-start1,4)                  \n",
    "    y_pred=tree.predict(x_test)       \n",
    "    \n",
    "    acc1=accuracy_score(y_test, y_pred)  \n",
    "    f1_1=f1_score(y_test, y_pred)        \n",
    "    \n",
    "    train_time_tree.append(time1)\n",
    "    accuracy_tree.append(acc1)\n",
    "    f1_tree.append(f1_1)\n",
    "    \n",
    "    #Logistic regression\n",
    "    start2=time()\n",
    "    logreg.fit(x_train,y_train)\n",
    "    stop2=time()\n",
    "    time2=round(stop2-start2,4)\n",
    "    y_pred=logreg.predict(x_test)\n",
    "\n",
    "    acc2=accuracy_score(y_test, y_pred)\n",
    "    f1_2=f1_score(y_test, y_pred)\n",
    "    \n",
    "    train_time_logreg.append(time2)\n",
    "    accuracy_logreg.append(acc2)\n",
    "    f1_logreg.append(f1_2)\n",
    "    \n",
    "    #Bayes\n",
    "    start3=time()\n",
    "    Bayes.fit(x_train,y_train)\n",
    "    stop3=time()\n",
    "    time3=round(stop3-start3,4)\n",
    "    y_pred=Bayes.predict(x_test)\n",
    "\n",
    "    acc3=accuracy_score(y_test, y_pred)\n",
    "    f1_3=f1_score(y_test, y_pred)\n",
    "    \n",
    "    train_time_Bayes.append(time3)\n",
    "    accuracy_Bayes.append(acc3)\n",
    "    f1_Bayes.append(f1_3)\n",
    "\n",
    "#converting to numpy arrays and adding mean and std dev at end of array\n",
    "train_time_tree=np.array(train_time_tree)\n",
    "avg=np.mean(train_time_tree)\n",
    "stddev=np.std(train_time_tree)\n",
    "train_time_tree=np.append(train_time_tree,avg)\n",
    "train_time_tree=np.append(train_time_tree,stddev)\n",
    "\n",
    "accuracy_tree=np.array(accuracy_tree)\n",
    "avg=np.mean(accuracy_tree)\n",
    "stddev=np.std(accuracy_tree)\n",
    "accuracy_tree=np.append(accuracy_tree,avg)\n",
    "accuracy_tree=np.append(accuracy_tree,stddev)\n",
    "\n",
    "f1_tree=np.array(f1_tree)\n",
    "avg=np.mean(f1_tree)\n",
    "stddev=np.std(f1_tree)\n",
    "f1_tree=np.append(f1_tree,avg)\n",
    "f1_tree=np.append(f1_tree,stddev)\n",
    "\n",
    "train_time_logreg=np.array(train_time_logreg)\n",
    "avg=np.mean(train_time_logreg)\n",
    "stddev=np.std(train_time_logreg)\n",
    "train_time_logreg=np.append(train_time_logreg,avg)\n",
    "train_time_logreg=np.append(train_time_logreg,stddev)\n",
    "\n",
    "accuracy_logreg=np.array(accuracy_logreg)\n",
    "avg=np.mean(accuracy_logreg)\n",
    "stddev=np.std(accuracy_logreg)\n",
    "accuracy_logreg=np.append(accuracy_logreg,avg)\n",
    "accuracy_logreg=np.append(accuracy_logreg,stddev)\n",
    "\n",
    "f1_logreg=np.array(f1_logreg)\n",
    "avg=np.mean(f1_logreg)\n",
    "stddev=np.std(f1_logreg)\n",
    "f1_logreg=np.append(f1_logreg,avg)\n",
    "f1_logreg=np.append(f1_logreg,stddev)\n",
    "\n",
    "train_time_Bayes=np.array(train_time_Bayes)\n",
    "avg=np.mean(train_time_Bayes)\n",
    "stddev=np.std(train_time_Bayes)\n",
    "train_time_Bayes=np.append(train_time_Bayes,avg)\n",
    "train_time_Bayes=np.append(train_time_Bayes,stddev)\n",
    "\n",
    "accuracy_Bayes=np.array(accuracy_Bayes)\n",
    "avg=np.mean(accuracy_Bayes)\n",
    "stddev=np.std(accuracy_Bayes)\n",
    "accuracy_Bayes=np.append(accuracy_Bayes,avg)\n",
    "accuracy_Bayes=np.append(accuracy_Bayes,stddev)\n",
    "\n",
    "f1_Bayes=np.array(f1_Bayes)\n",
    "avg=np.mean(f1_Bayes)\n",
    "stddev=np.std(f1_Bayes)\n",
    "f1_Bayes=np.append(f1_Bayes,avg)\n",
    "f1_Bayes=np.append(f1_Bayes,stddev)\n",
    "\n",
    "#making dicts to store metrics of each model\n",
    "\n",
    "train_time_dict={'tree': train_time_tree ,'logreg': train_time_logreg, 'Bayes': train_time_Bayes }\n",
    "acc_dict={'tree': accuracy_tree ,'logreg': accuracy_logreg, 'Bayes': accuracy_Bayes }\n",
    "f1_dict={'tree': f1_tree ,'logreg': f1_logreg, 'Bayes':f1_Bayes }\n",
    "\n",
    "index_array=[]\n",
    "for i in range(1,11):\n",
    "    index_array.append(str(i))\n",
    "\n",
    "index_array.append('avg')\n",
    "index_array.append('std_dev')\n",
    "\n",
    "#making dataframes from the recorded metrics and making a rank based version of these dataframes \n",
    "\n",
    "acc_df = pd.DataFrame(acc_dict, index=index_array)\n",
    "print(acc_df)\n",
    "traintime_df = pd.DataFrame(train_time_dict, index=index_array)\n",
    "print(traintime_df)\n",
    "f1_df = pd.DataFrame(f1_dict, index=index_array)\n",
    "print(f1_df)\n",
    "\n",
    "acc_df=acc_df.rank(axis=1,method='dense',ascending=False)\n",
    "acc_df=acc_df.drop(['avg','std_dev'])\n",
    "acc_df.loc['avg_rank']=acc_df.mean()\n",
    "print(acc_df)\n",
    "dummy=acc_df.mean(axis=1)\n",
    "avg_rank_acc=dummy[-1]\n",
    "\n",
    "dummy=acc_df['tree']\n",
    "a1=dummy[-1]\n",
    "dummy=acc_df['logreg']\n",
    "a2=dummy[-1]\n",
    "dummy=acc_df['Bayes']\n",
    "a3=dummy[-1]\n",
    "\n",
    "\n",
    "#sum squared difference\n",
    "sum_sq=((a1-avg_rank_acc)*(a1-avg_rank_acc)) + ((a2-avg_rank_acc)*(a2-avg_rank_acc)) + ((a3-avg_rank_acc)*(a3-avg_rank_acc))\n",
    "sum_sq=10*sum_sq\n",
    "\n",
    "\n",
    "\n",
    "acc_df=acc_df.drop(['avg_rank'])\n",
    "acc_np=acc_df.to_numpy()\n",
    "dummy=acc_np-2\n",
    "dummy=np.square(dummy)\n",
    "sum_sq2=np.sum(dummy)\n",
    "sum_sq2=sum_sq2/20\n",
    "f_no1=sum_sq/sum_sq2\n",
    "\n",
    "print('friedman statistic : '+str(f_no1))\n",
    "\n",
    "crit_val=7.8 #for k=3, n = 10 and alpha = 0.05\n",
    "\n",
    "if f_no1>crit_val:\n",
    "    print(\"There  is  statistically  significant difference in behaviour between the three models. Null Hypothesis is rejected\")\n",
    "else:\n",
    "    print(\"There is no difference in behaviour between three models\")\n",
    "\n",
    "q_alpha=2.343 #from text book\n",
    "k=3\n",
    "n=10\n",
    "alpha=0.05\n",
    "\n",
    "crit_diff=q_alpha*sqrt(k*(k+1)/(6*n))\n",
    "\n",
    "print(\"The critical difference is :\" + str(crit_diff))\n",
    "if abs(a1-a2)>crit_diff:\n",
    "    print(\"The performance of Decision Tree and Logistic Regression is not equivalent.\")\n",
    "    \n",
    "if abs(a1-a3)>crit_diff:\n",
    "    print(\"The performance of Decision Tree and Bayes is not equivalent.\")\n",
    "\n",
    "if abs(a2-a3)>crit_diff:\n",
    "    print(\"The performance of Bayes and Logistic Regression is not equivalent.\")\n",
    "\n",
    "\n",
    "traintime_df=traintime_df.rank(axis=1,method='dense',ascending=True)\n",
    "traintime_df=traintime_df.drop(['avg','std_dev'])\n",
    "traintime_df.loc['avg_rank']=traintime_df.mean()\n",
    "print(traintime_df)\n",
    "dummy=traintime_df.mean(axis=1)\n",
    "avg_rank_acc=dummy[-1]\n",
    "\n",
    "dummy=traintime_df['tree']\n",
    "b1=dummy[-1]\n",
    "dummy=traintime_df['logreg']\n",
    "b2=dummy[-1]\n",
    "dummy=traintime_df['Bayes']\n",
    "b3=dummy[-1]\n",
    "\n",
    "sum_sq=((b1-avg_rank_acc)*(b1-avg_rank_acc)) + ((b2-avg_rank_acc)*(b2-avg_rank_acc)) + ((b3-avg_rank_acc)*(b3-avg_rank_acc))\n",
    "sum_sq=10*sum_sq\n",
    "\n",
    "traintime_df=traintime_df.drop(['avg_rank'])\n",
    "acc_np=traintime_df.to_numpy()\n",
    "dummy=acc_np-2\n",
    "dummy=np.square(dummy)\n",
    "sum_sq2=np.sum(dummy)\n",
    "sum_sq2=sum_sq2/20\n",
    "f_no2=sum_sq/sum_sq2\n",
    "\n",
    "print('friedman statistic : '+str(f_no2))\n",
    "\n",
    "crit_val=7.8 #for k=3, n = 10 and alpha = 0.05\n",
    "\n",
    "if f_no2>crit_val:\n",
    "    print(\"There  is  statistically  significant difference in behaviour between the three models. Null Hypothesis is rejected\")\n",
    "else:\n",
    "    print(\"There is no difference in behaviour between three models\")\n",
    "\n",
    "q_alpha=2.343\n",
    "k=3\n",
    "n=10\n",
    "alpha=0.05\n",
    "\n",
    "crit_diff=q_alpha*sqrt(k*(k+1)/(6*n))\n",
    "\n",
    "print(\"The critical difference is :\" + str(crit_diff))\n",
    "if abs(b1-b2)>crit_diff:\n",
    "    print(\"The performance of Decision Tree and Logistic Regression is not equivalent.\")\n",
    "\n",
    "if abs(b1-b3)>crit_diff:\n",
    "    print(\"The performance of Decision Tree and Bayes is not equivalent.\")\n",
    "\n",
    "\n",
    "if abs(b2-b3)>crit_diff:\n",
    "    print(\"The performance of Bayes and Logistic Regression is not equivalent.\")\n",
    "\n",
    "\n",
    "f1_df=f1_df.rank(axis=1,method='dense',ascending=False)\n",
    "f1_df=f1_df.drop(['avg','std_dev'])\n",
    "f1_df.loc['avg_rank']=f1_df.mean()\n",
    "print(f1_df)\n",
    "dummy=f1_df.mean(axis=1)\n",
    "avg_rank_acc=dummy[-1]\n",
    "\n",
    "dummy=f1_df['tree']\n",
    "c1=dummy[-1]\n",
    "dummy=f1_df['logreg']\n",
    "c2=dummy[-1]\n",
    "dummy=f1_df['Bayes']\n",
    "c3=dummy[-1]\n",
    "\n",
    "sum_sq=((c1-avg_rank_acc)*(c1-avg_rank_acc)) + ((c2-avg_rank_acc)*(c2-avg_rank_acc)) + ((c3-avg_rank_acc)*(c3-avg_rank_acc))\n",
    "sum_sq=10*sum_sq\n",
    "\n",
    "f1_df=f1_df.drop(['avg_rank'])\n",
    "acc_np=f1_df.to_numpy()\n",
    "dummy=acc_np-2\n",
    "dummy=np.square(dummy)\n",
    "sum_sq2=np.sum(dummy)\n",
    "sum_sq2=sum_sq2/20\n",
    "\n",
    "f_no3=sum_sq/sum_sq2\n",
    "\n",
    "print('friedman statistic : '+str(f_no3))\n",
    "\n",
    "crit_val=7.8 #for k=3, n = 10 and alpha = 0.05\n",
    "\n",
    "if f_no3>crit_val:\n",
    "    print(\"There  is  statistically  significant difference in behaviour between the three models. Null Hypothesis is rejected\")\n",
    "else:\n",
    "    print(\"There is no difference in behaviour between three models\")\n",
    "\n",
    "q_alpha=2.343\n",
    "k=3\n",
    "n=10\n",
    "alpha=0.05\n",
    "\n",
    "crit_diff=q_alpha*sqrt(k*(k+1)/(6*n))\n",
    "\n",
    "print(\"The critical difference is :\" + str(crit_diff))\n",
    "if abs(c1-c2)>crit_diff:\n",
    "    print(\"The performance of Decision Tree and Logistic Regression is not equivalent.\")\n",
    "\n",
    "    \n",
    "if abs(c1-c3)>crit_diff:\n",
    "    print(\"The performance of Decision Tree and Bayes is not equivalent.\")\n",
    "\n",
    "\n",
    "if abs(c2-c3)>crit_diff:\n",
    "    print(\"The performance of Bayes and Logistic Regression is not equivalent.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jg4LFYeD0A3l"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "MLA2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
